{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pi = math.pi\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_feature_matrix(X):\n",
    "    min_X = X.min(axis=1)[:,None]\n",
    "    max_X = X.max(axis=1)[:,None]\n",
    "    \n",
    "    return (X- min_X) / (max_X - min_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 count = 112 patients. \n",
      "Class 1 count = 32 patients. \n",
      "Class 2 count = 0 patients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>T</th>\n",
       "      <th>N</th>\n",
       "      <th>M</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>R01-001</td>\n",
       "      <td>T1a</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>R01-002</td>\n",
       "      <td>T1a</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>R01-003</td>\n",
       "      <td>T3</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>R01-004</td>\n",
       "      <td>T1b</td>\n",
       "      <td>N2</td>\n",
       "      <td>M0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>R01-005</td>\n",
       "      <td>T2a</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>R01-006</td>\n",
       "      <td>T1b</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>R01-007</td>\n",
       "      <td>T1a</td>\n",
       "      <td>N1</td>\n",
       "      <td>M0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>R01-008</td>\n",
       "      <td>Tis</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>R01-010</td>\n",
       "      <td>T3</td>\n",
       "      <td>N0</td>\n",
       "      <td>M0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>R01-011</td>\n",
       "      <td>T1a</td>\n",
       "      <td>N2</td>\n",
       "      <td>M0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID    T   N   M  label\n",
       "49  R01-001  T1a  N0  M0      0\n",
       "50  R01-002  T1a  N0  M0      0\n",
       "51  R01-003   T3  N0  M0      0\n",
       "52  R01-004  T1b  N2  M0      1\n",
       "53  R01-005  T2a  N0  M0      0\n",
       "54  R01-006  T1b  N0  M0      0\n",
       "55  R01-007  T1a  N1  M0      1\n",
       "56  R01-008  Tis  N0  M0      0\n",
       "58  R01-010   T3  N0  M0      0\n",
       "59  R01-011  T1a  N2  M0      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_data = pd.read_csv('NSCLCR01Radiogenomic_DATA_LABELS_2018-05-22_1500-shifted.csv')\n",
    "clinical_data = clinical_data.loc[clinical_data['Case ID']>='R01-001'] #Dropping AMC patients\n",
    "clinical_data = clinical_data.loc[clinical_data['Case ID']<='R01-146'] #Dropping the rest of R01 patients (with no CT)\n",
    "\n",
    "clinical_data = clinical_data[['Case ID', 'Pathological T stage',\n",
    "                               'Pathological N stage', 'Pathological M stage']] #Dropping all irrelavant info\n",
    "\n",
    "clinical_data.rename(columns = {'Case ID': 'ID',\n",
    "                                'Pathological T stage': 'T',\n",
    "                               'Pathological N stage' : 'N',\n",
    "                               'Pathological M stage' : 'M'}, inplace = True)\n",
    "\n",
    "# Dropping two patients who had no CT:\n",
    "clinical_data = clinical_data[clinical_data.ID != 'R01-009']\n",
    "clinical_data = clinical_data[clinical_data.ID != 'R01-143']\n",
    "\n",
    "clinical_data['label'] = 0\n",
    "clinical_data.loc[clinical_data.M != 'M0', 'label'] = 2\n",
    "clinical_data.loc[(clinical_data.M != 'M0') | (clinical_data.N != 'N0'), 'label'] = 1\n",
    "\n",
    "label0_count = clinical_data[(clinical_data.label == 0)].count()[0]\n",
    "label1_count = clinical_data[(clinical_data.label == 1)].count()[0]\n",
    "label2_count = clinical_data[(clinical_data.label == 2)].count()[0]\n",
    "print('Class 0 count = %d patients. \\nClass 1 count = %d patients. \\nClass 2 count = %d patients'%\n",
    "      (label0_count, label1_count, label2_count))\n",
    "clinical_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = clinical_data.iloc[:,-1].values\n",
    "patients_names = clinical_data.iloc[:,0].values\n",
    "del clinical_data\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 14) (144, 8) (144, 22)\n"
     ]
    }
   ],
   "source": [
    "Statistcal_features = np.load(open('Statistical_no_surrouding', 'rb'))\n",
    "Shape_size_features = np.load(open('Shape_size_features', 'rb'))\n",
    "All_features = np.hstack((Statistcal_features, Shape_size_features))\n",
    "\n",
    "print(Statistcal_features.shape, Shape_size_features.shape, All_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49402893e+09  1.80788842e+05  5.80062329e+02  1.39000000e+03\n",
      "  9.49934670e+02 -1.17544920e+07  1.04500000e+03  7.50000000e+01\n",
      "  1.31500000e+03  9.83048078e+02 -3.49964940e-01  3.10159332e+02\n",
      "  1.53783688e+08  7.29123326e+06]\n",
      "[8.82410318e+00 4.17916966e-01 5.68950109e+02 1.33752939e+00\n",
      " 7.47647125e-01 7.80750084e+02 5.88742199e-01 1.32613236e+03]\n",
      "[ 1.49402893e+09  1.80788842e+05  5.80062329e+02  1.39000000e+03\n",
      "  9.49934670e+02 -1.17544920e+07  1.04500000e+03  7.50000000e+01\n",
      "  1.31500000e+03  9.83048078e+02 -3.49964940e-01  3.10159332e+02\n",
      "  1.53783688e+08  7.29123326e+06  8.82410318e+00  4.17916966e-01\n",
      "  5.68950109e+02  1.33752939e+00  7.47647125e-01  7.80750084e+02\n",
      "  5.88742199e-01  1.32613236e+03]\n",
      "\n",
      "\n",
      "[ 6.47869133e+09  4.60459695e+05  9.18095849e+01  1.48600000e+03\n",
      "  8.64472926e+02 -2.22117640e+07  1.00200000e+03  1.52000000e+02\n",
      "  1.33400000e+03  9.01149048e+02 -5.39981893e-01  3.87883850e+02\n",
      "  6.74854584e+08  2.47186848e+06]\n",
      "[3.34023634e+01 6.54094797e-01 2.60451518e+03 1.15200165e+00\n",
      " 8.68054311e-01 2.94787841e+03 2.42187128e-01 1.21719038e+04]\n",
      "[ 6.47869133e+09  4.60459695e+05  9.18095849e+01  1.48600000e+03\n",
      "  8.64472926e+02 -2.22117640e+07  1.00200000e+03  1.52000000e+02\n",
      "  1.33400000e+03  9.01149048e+02 -5.39981893e-01  3.87883850e+02\n",
      "  6.74854584e+08  2.47186848e+06  3.34023634e+01  6.54094797e-01\n",
      "  2.60451518e+03  1.15200165e+00  8.68054311e-01  2.94787841e+03\n",
      "  2.42187128e-01  1.21719038e+04]\n",
      "\n",
      "\n",
      "[ 2.27457384e+11  1.91839746e+07  3.59954679e+00  2.03500000e+03\n",
      "  9.38549806e+02 -7.33818112e+08  1.06900000e+03  7.90000000e+01\n",
      "  1.95600000e+03  9.72110388e+02 -5.40835758e-01  4.16692841e+02\n",
      "  6.35405316e+11  2.92552492e+06]\n",
      "[7.28570047e+01 2.36941433e-01 2.31699415e+04 1.61604331e+00\n",
      " 6.18795296e-01 1.38210907e+04 1.85838000e-01 7.43717145e+04]\n",
      "[ 2.27457384e+11  1.91839746e+07  3.59954679e+00  2.03500000e+03\n",
      "  9.38549806e+02 -7.33818112e+08  1.06900000e+03  7.90000000e+01\n",
      "  1.95600000e+03  9.72110388e+02 -5.40835758e-01  4.16692841e+02\n",
      "  6.35405316e+11  2.92552492e+06  7.28570047e+01  2.36941433e-01\n",
      "  2.31699415e+04  1.61604331e+00  6.18795296e-01  1.38210907e+04\n",
      "  1.85838000e-01  7.43717145e+04]\n"
     ]
    }
   ],
   "source": [
    "print(Statistcal_features[3])\n",
    "print(Shape_size_features[3])\n",
    "print(All_features[3])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(Statistcal_features[50])\n",
    "print(Shape_size_features[50])\n",
    "print(All_features[50])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(Statistcal_features[143])\n",
    "print(Shape_size_features[143])\n",
    "print(All_features[143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5 is the validation fold:\n",
      "MLP accuracy:  80.0 %\n",
      "MLP FN:  71.42857142857143\n",
      "Logistic regression accuracy:  60.0 %\n",
      "Logistic regression False negative:  71.42857142857143 %\n",
      "SVM accuracy:  63.33333333333333 %\n",
      "SVM False Negative:  57.14285714285714 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/5 is the validation fold:\n",
      "MLP accuracy:  83.33333333333334 %\n",
      "MLP FN:  85.71428571428572\n",
      "Logistic regression accuracy:  76.66666666666667 %\n",
      "Logistic regression False negative:  42.85714285714286 %\n",
      "SVM accuracy:  73.33333333333333 %\n",
      "SVM False Negative:  42.85714285714286 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/5 is the validation fold:\n",
      "MLP accuracy:  67.85714285714286 %\n",
      "MLP FN:  66.66666666666667\n",
      "Logistic regression accuracy:  71.42857142857143 %\n",
      "Logistic regression False negative:  33.333333333333336 %\n",
      "SVM accuracy:  71.42857142857143 %\n",
      "SVM False Negative:  33.333333333333336 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/5 is the validation fold:\n",
      "MLP accuracy:  64.28571428571429 %\n",
      "MLP FN:  66.66666666666667\n",
      "Logistic regression accuracy:  53.57142857142857 %\n",
      "Logistic regression False negative:  50.0 %\n",
      "SVM accuracy:  60.71428571428571 %\n",
      "SVM False Negative:  16.666666666666664 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/5 is the validation fold:\n",
      "MLP accuracy:  85.71428571428571 %\n",
      "MLP FN:  83.33333333333334\n",
      "Logistic regression accuracy:  64.28571428571429 %\n",
      "Logistic regression False negative:  33.333333333333336 %\n",
      "SVM accuracy:  57.14285714285714 %\n",
      "SVM False Negative:  66.66666666666667 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 1/5 is the validation fold:\n",
      "MLP accuracy:  63.33333333333333 %\n",
      "MLP FN:  100.0\n",
      "Logistic regression accuracy:  43.333333333333336 %\n",
      "Logistic regression False negative:  71.42857142857143 %\n",
      "SVM accuracy:  40.0 %\n",
      "SVM False Negative:  57.14285714285714 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/5 is the validation fold:\n",
      "MLP accuracy:  70.0 %\n",
      "MLP FN:  85.71428571428572\n",
      "Logistic regression accuracy:  56.666666666666664 %\n",
      "Logistic regression False negative:  28.57142857142857 %\n",
      "SVM accuracy:  53.333333333333336 %\n",
      "SVM False Negative:  28.57142857142857 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/5 is the validation fold:\n",
      "MLP accuracy:  57.14285714285714 %\n",
      "MLP FN:  100.0\n",
      "Logistic regression accuracy:  57.14285714285714 %\n",
      "Logistic regression False negative:  50.0 %\n",
      "SVM accuracy:  32.142857142857146 %\n",
      "SVM False Negative:  50.0 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/5 is the validation fold:\n",
      "MLP accuracy:  64.28571428571429 %\n",
      "MLP FN:  66.66666666666667\n",
      "Logistic regression accuracy:  42.857142857142854 %\n",
      "Logistic regression False negative:  33.333333333333336 %\n",
      "SVM accuracy:  42.857142857142854 %\n",
      "SVM False Negative:  33.333333333333336 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/5 is the validation fold:\n",
      "MLP accuracy:  75.0 %\n",
      "MLP FN:  83.33333333333334\n",
      "Logistic regression accuracy:  53.57142857142857 %\n",
      "Logistic regression False negative:  0.0 %\n",
      "SVM accuracy:  28.57142857142857 %\n",
      "SVM False Negative:  0.0 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 1/5 is the validation fold:\n",
      "MLP accuracy:  66.66666666666666 %\n",
      "MLP FN:  85.71428571428572\n",
      "Logistic regression accuracy:  60.0 %\n",
      "Logistic regression False negative:  71.42857142857143 %\n",
      "SVM accuracy:  63.33333333333333 %\n",
      "SVM False Negative:  57.14285714285714 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/5 is the validation fold:\n",
      "MLP accuracy:  73.33333333333333 %\n",
      "MLP FN:  85.71428571428572\n",
      "Logistic regression accuracy:  76.66666666666667 %\n",
      "Logistic regression False negative:  42.85714285714286 %\n",
      "SVM accuracy:  73.33333333333333 %\n",
      "SVM False Negative:  42.85714285714286 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/5 is the validation fold:\n",
      "MLP accuracy:  50.0 %\n",
      "MLP FN:  66.66666666666667\n",
      "Logistic regression accuracy:  71.42857142857143 %\n",
      "Logistic regression False negative:  33.333333333333336 %\n",
      "SVM accuracy:  71.42857142857143 %\n",
      "SVM False Negative:  33.333333333333336 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/5 is the validation fold:\n",
      "MLP accuracy:  60.71428571428571 %\n",
      "MLP FN:  100.0\n",
      "Logistic regression accuracy:  53.57142857142857 %\n",
      "Logistic regression False negative:  50.0 %\n",
      "SVM accuracy:  60.71428571428571 %\n",
      "SVM False Negative:  16.666666666666664 %\n",
      "\n",
      "\n",
      "\n",
      "Fold 5/5 is the validation fold:\n",
      "MLP accuracy:  89.28571428571429 %\n",
      "MLP FN:  83.33333333333334\n",
      "Logistic regression accuracy:  64.28571428571429 %\n",
      "Logistic regression False negative:  33.333333333333336 %\n",
      "SVM accuracy:  57.14285714285714 %\n",
      "SVM False Negative:  66.66666666666667 %\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "experiments = [Statistcal_features, Shape_size_features, All_features]\n",
    "experiments_names = ['Statistcal_features', 'Shape_size_features', 'All_features']\n",
    "results = open(\"Results.txt\", 'w+')\n",
    "\n",
    "results.write(\"Tumor without surronding environment\\n\")\n",
    "for e, experiment in enumerate(experiments):\n",
    "    results.write(experiments_names[e]+':\\n')\n",
    "    features_matrix = experiment\n",
    "    if not np.array_equal(features_matrix[:,-1],labels): features_matrix = np.hstack((features_matrix, labels[:,None]))\n",
    "\n",
    "    X0 = features_matrix[features_matrix[:,-1]==0]\n",
    "    X1 = features_matrix[features_matrix[:,-1]==1]\n",
    "\n",
    "    X0_folds = np.array_split(X0, k)\n",
    "    X1_folds = np.array_split(X1, k)\n",
    "\n",
    "    Avg_acc_MLP, Avg_fn = 0, 0\n",
    "    Avg_acc_logistic_regression, Avg_acc_SVM = 0, 0\n",
    "    Logistic_reg_fn, SVM_FN = 0, 0\n",
    "\n",
    "    for i in range(k):\n",
    "        print('Fold %d/%d is the validation fold:'%(i+1, k))\n",
    "\n",
    "        X0_train = np.concatenate([X0_folds[j] for j in range(k) if j!=i])\n",
    "        X1_train = np.concatenate([X1_folds[j] for j in range(k) if j!=i])\n",
    "\n",
    "        X0_val = X0_folds[i]\n",
    "        X1_val = X1_folds[i]\n",
    "\n",
    "        x_train = np.concatenate((X0_train, X1_train), axis=0)\n",
    "        x_val = np.concatenate((X0_val, X1_val), axis=0)\n",
    "\n",
    "        np.random.shuffle(x_train)\n",
    "        np.random.shuffle(x_val)\n",
    "\n",
    "        y_train = x_train[:,-1]\n",
    "        y_val = x_val[:,-1]\n",
    "\n",
    "        x_train = x_train[:,:-1]\n",
    "        x_val = x_val[:,:-1]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        x_train_mlp = scaler.transform(x_train)\n",
    "        x_val_mlp = scaler.transform(x_val)\n",
    "\n",
    "\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-10, hidden_layer_sizes=(1000, 100, 100), random_state=1, max_iter=500)\n",
    "        clf.fit(x_train_mlp, y_train)\n",
    "\n",
    "        MLP_result = clf.score(x_val_mlp, y_val)*100\n",
    "\n",
    "        print('MLP accuracy: ', MLP_result, '%')\n",
    "\n",
    "        Avg_acc_MLP += MLP_result\n",
    "\n",
    "        nm = np.asarray(np.where(y_val==1))\n",
    "        nm = nm.reshape(nm.size)\n",
    "        fn = (1-clf.score(x_train_mlp[nm], y_val[nm]))*100\n",
    "        print('MLP FN: ', fn)\n",
    "        Avg_fn += fn\n",
    "        \n",
    "        x_train = standardize_feature_matrix(x_train)\n",
    "        x_val = standardize_feature_matrix(x_val)\n",
    "        \n",
    "        clf2 = LogisticRegression(class_weight= 'balanced', solver='liblinear')\n",
    "        clf2.fit(x_train, y_train)\n",
    "\n",
    "        Logistic_regression_result = clf2.score(x_val, y_val)*100\n",
    "        log_reg_fn = (1-clf2.score(x_val[nm], y_val[nm]))*100\n",
    "\n",
    "        print('Logistic regression accuracy: ', Logistic_regression_result, '%')\n",
    "        print('Logistic regression False negative: ', log_reg_fn, '%')\n",
    "\n",
    "        clf3 = SVC(kernel='linear', class_weight='balanced')\n",
    "        clf3.fit(x_train, y_train)\n",
    "\n",
    "        SVM_result = clf3.score(x_val, y_val)*100\n",
    "        SVM_fn = (1-clf3.score(x_val[nm], y_val[nm]))*100\n",
    "\n",
    "        print('SVM accuracy: ', SVM_result, '%')\n",
    "        print('SVM False Negative: ', SVM_fn, '%\\n\\n\\n')\n",
    "        \n",
    "        Avg_acc_logistic_regression += Logistic_regression_result\n",
    "        Avg_acc_SVM += SVM_result\n",
    "\n",
    "        Logistic_reg_fn += log_reg_fn\n",
    "        SVM_FN += SVM_fn\n",
    "\n",
    "\n",
    "    Avg_acc_MLP /= k\n",
    "    Avg_fn /= k\n",
    "    Avg_acc_logistic_regression /= k\n",
    "    Avg_acc_SVM /= k\n",
    "    Logistic_reg_fn /= k\n",
    "    SVM_FN /= k\n",
    "\n",
    "    results.write('\\t\\t| Average MLP accuracy:                 '+ str(Avg_acc_MLP)+ '% |\\n')\n",
    "    results.write('\\t| Average false negative:               '+ str(Avg_fn)+ '% |\\n')\n",
    "    results.write('\\t\\t| Average logistic regression accuracy: '+ str(Avg_acc_logistic_regression)+ '% |\\n')\n",
    "    results.write('\\t| Average logistic regression FN:       '+ str(Logistic_reg_fn)+ '% |\\n')\n",
    "    results.write('\\t\\t| Average SVM accuracy:                 '+ str(Avg_acc_SVM)+ '% |\\n')\n",
    "    results.write('\\t| Average SVM FN:                       '+ str(SVM_FN)+ '% |\\n')\n",
    "    results.write('\\t\\t\\t ------------------------------------------------------------\\n\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.52380952380952 71.47619047619048 74.38095238095238\n",
      "62.38095238095239 52.38095238095239 83.80952380952382\n"
     ]
    }
   ],
   "source": [
    "print(Avg_acc_MLP, Avg_acc_logistic_regression, Avg_acc_SVM)\n",
    "print(Avg_fn, Logistic_reg_fn, SVM_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
